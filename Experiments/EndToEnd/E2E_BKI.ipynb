{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9714d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Segmentation.spvcnn import *\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.utils.quantize import sparse_quantize\n",
    "from torchsparse.utils.collate import sparse_collate\n",
    "from ConvBKI.ConvBKI import *\n",
    "from Propagation.mapping_utils import *\n",
    "from BKINet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cce855b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "Loading nuScenes-lidarseg...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "404 lidarseg,\n",
      "Done loading in 0.262 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "from nuscenes.utils.data_classes import LidarSegPointCloud\n",
    "from nuscenes.utils.data_io import load_bin_file\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import transform_matrix\n",
    "data_dir = '/home/tigeriv/Data/nuscenes_mini'\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot=data_dir, verbose=True)\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5b50cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "dtype=torch.float32\n",
    "\n",
    "voxel_sizes = torch.tensor([0.25, 0.25, 0.25]).to(dev)\n",
    "\n",
    "grid_size = torch.tensor([200, 200, 20]).to(dev)\n",
    "min_bound = torch.tensor([-25., -25., -3.5]).to(dev)\n",
    "max_bound = torch.tensor([25., 25., 1.5]).to(dev)\n",
    "\n",
    "num_classes = 13\n",
    "\n",
    "f = 5\n",
    "\n",
    "seg_path = \"/home/tigeriv/Code/NuScenesConvBKI/spvnas/runs/Downsampled/checkpoints/max-iou-test.pt\"\n",
    "\n",
    "COLOR_MAP = np.array(['#f59664', '#f5e664', '#963c1e', '#b41e50', '#ff0000',\n",
    "                      '#1e1eff', '#c828ff', '#5a1e96', '#ff00ff', '#ff96ff',\n",
    "                      '#4b004b', '#4b00af', '#00c8ff', '#3278ff', '#00af00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96690dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segmentation network\n",
    "seg_net = SPVCNN(\n",
    "    num_classes=num_classes,\n",
    "    cr=0.5,\n",
    "    pres=0.05,\n",
    "    vres=0.05).to(dev)\n",
    "\n",
    "seg_net.load_state_dict(torch.load(seg_path)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5f3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagation network\n",
    "prop_net = TransformWorldStatic(voxel_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f3b067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tigeriv/.local/lib/python3.8/site-packages/torch/functional.py:1069: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.cartesian_prod(tensors)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# ConvBKI network\n",
    "bki_layer = ConvBKI(grid_size, min_bound, max_bound, \n",
    "                    filter_size=f, num_classes=num_classes, device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99faecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End to End Network\n",
    "e2e_net = BKINet(seg_net, bki_layer, prop_net, grid_size, device=dev, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdf7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lidar(curr_sample):\n",
    "    # Load lidar pc\n",
    "    lidar_data = nusc.get('sample_data', curr_sample['data']['LIDAR_TOP'])\n",
    "    ego_pose = nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "    lidar_pose = transform_matrix(translation=ego_pose['translation'], rotation=Quaternion(ego_pose['rotation']))\n",
    "    \n",
    "    lidar_fpath = os.path.join(data_dir, lidar_data['filename'])\n",
    "    label_data = nusc.get('lidarseg', curr_sample['data']['LIDAR_TOP'])\n",
    "    label_fpath = os.path.join(data_dir, label_data['filename'])\n",
    "\n",
    "    labeled_pc = LidarSegPointCloud(points_path=lidar_fpath, labels_path=label_fpath)\n",
    "    return lidar_pose, labeled_pc\n",
    "    \n",
    "\n",
    "def generate_seg_in(lidar):\n",
    "    # Create input data\n",
    "    coords = np.round(lidar[:, :3] / 0.05)\n",
    "    coords -= coords.min(0, keepdims=1)\n",
    "    feats = lidar\n",
    "    # Filter out duplicate points\n",
    "    coords, indices, inverse = sparse_quantize(coords, return_index=True, return_inverse=True)\n",
    "    coords = torch.tensor(coords, dtype=torch.int)\n",
    "    feats = torch.tensor(feats[indices], dtype=torch.float)\n",
    "\n",
    "    inputs = SparseTensor(coords=coords, feats=feats)\n",
    "    inputs = sparse_collate([inputs]).cuda()\n",
    "    return inputs, inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad87e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test by loading weights for segmentation, freezing everything\n",
    "# and running on nuScenes\n",
    "curr_scene = nusc.scene[2]\n",
    "\n",
    "sample_token = curr_scene['first_sample_token']\n",
    "curr_sample = nusc.get('sample', sample_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0f13c21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "curr_sample = nusc.get('sample', curr_sample['next'])\n",
    "\n",
    "lidar_pose, labeled_pc = get_lidar(curr_sample)\n",
    "lidar = labeled_pc.points\n",
    "seg_input, inv = generate_seg_in(lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68150443",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_points = seg_net(seg_input)[inv]\n",
    "outputs = labeled_points.argmax(1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67adca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_net.requires_grad = False\n",
    "lidar[:, 3] = 1\n",
    "input_data = [torch.tensor(lidar_pose).to(dev).type(dtype), torch.tensor(lidar).to(dev).type(dtype),\n",
    "              seg_input, torch.tensor(inv).to(dev)]\n",
    "e2e_net(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7efcd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lidar predictions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def configure_plotly_browser_state():\n",
    "    import IPython\n",
    "    display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))\n",
    "\n",
    "def plot_lidar_preds(lidar):\n",
    "    trace = go.Scatter3d(\n",
    "        x=lidar[:, 0],\n",
    "        y=lidar[:, 1],\n",
    "        z=lidar[:, 2],\n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'size': 1,\n",
    "            'opacity': 0.8,\n",
    "            'color': COLOR_MAP[outputs].tolist(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    configure_plotly_browser_state()\n",
    "    plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "    layout = go.Layout(\n",
    "        margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "        scene=dict(aspectmode='manual', aspectratio=dict(x=1, y=1, z=0.2))\n",
    "    )\n",
    "\n",
    "    plotly.offline.iplot(go.Figure(data=[trace], layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69320e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
